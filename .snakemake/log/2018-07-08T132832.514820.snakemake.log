Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	R
	1	all
	1	importCSV
	1	preprocess
	4

rule importCSV:
    input: Inputs/DiaryU104408808.csv
    output: Outputs/RawData.csv
    jobid: 1


rule R:
    input: bg-calc.R
    output: Outputs/bg-graph.png
    jobid: 3

Finished job 1.
1 of 4 steps (25%) done

rule preprocess:
    input: preprocess.sh, Outputs/RawData.csv
    output: Outputs/processed.tsv
    jobid: 2

Finished job 2.
2 of 4 steps (50%) done
Finished job 3.
3 of 4 steps (75%) done

localrule all:
    input: Outputs/RawData.csv, Outputs/processed.tsv, Outputs/bg-graph.png
    jobid: 0

Finished job 0.
4 of 4 steps (100%) done
Complete log: /data/.snakemake/log/2018-07-08T132832.514820.snakemake.log
